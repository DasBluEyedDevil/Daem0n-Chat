---
phase: 04-auto-detection-memory-decay
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - daem0nmcp/memory.py
  - daem0nmcp/auto_detect.py
  - daem0nmcp/config.py
  - tests/test_auto_detect.py
  - tests/test_similarity.py
autonomous: true

must_haves:
  truths:
    - "Non-permanent memories decay at category-specific rates (interest/goal=90d, emotion/concern=30d, context=14d)"
    - "Auto-detected memories tagged 'auto' decay 30% faster than explicit memories of the same category"
    - "Noise content (greetings, filler, acknowledgments) is rejected before storage"
    - "Confidence routing works: >=0.95 auto-stores, 0.70-0.95 suggests, <0.70 skips"
  artifacts:
    - path: "daem0nmcp/auto_detect.py"
      provides: "Noise filter, confidence routing, constants"
      exports: ["validate_auto_memory", "NOISE_PATTERNS", "MIN_CONTENT_LENGTH", "MIN_WORD_COUNT", "DUPLICATE_SIMILARITY_THRESHOLD", "AUTO_DECAY_MULTIPLIER", "CATEGORY_HALF_LIVES"]
    - path: "daem0nmcp/memory.py"
      provides: "Per-category decay scoring in recall()"
      contains: "CATEGORY_HALF_LIVES"
    - path: "daem0nmcp/config.py"
      provides: "Configurable auto-detection thresholds"
      contains: "auto_detect_confidence_high"
    - path: "tests/test_auto_detect.py"
      provides: "Tests for noise filter, confidence routing, decay rates"
  key_links:
    - from: "daem0nmcp/memory.py"
      to: "daem0nmcp/auto_detect.py"
      via: "import CATEGORY_HALF_LIVES, AUTO_DECAY_MULTIPLIER"
      pattern: "from.*auto_detect.*import"
    - from: "daem0nmcp/memory.py"
      to: "daem0nmcp/similarity.py"
      via: "calculate_memory_decay with per-category half_life"
      pattern: "calculate_memory_decay.*effective_half_life"
---

<objective>
Fix the per-category memory decay bug and create the auto-detection validation infrastructure.

Purpose: The recall scoring currently applies a single 30-day half-life to ALL non-permanent memories despite SLOW_DECAY_CATEGORIES (90d) and FAST_DECAY_CATEGORIES (30d/14d) being defined in models.py. This plan fixes that bug, adds source-based decay differentiation (auto-detected memories decay faster), and creates the server-side noise filter + confidence routing module that Plan 02 will wire into daem0n_remember.

Output: Fixed per-category decay in recall(), new daem0nmcp/auto_detect.py module, config settings for thresholds, comprehensive tests.
</objective>

<execution_context>
@C:\Users\dasbl\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\dasbl\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-auto-detection-memory-decay/04-RESEARCH.md
@daem0nmcp/models.py (lines 20-36: VALID_CATEGORIES, PERMANENT_CATEGORIES, SLOW_DECAY_CATEGORIES, FAST_DECAY_CATEGORIES)
@daem0nmcp/memory.py (lines 1210-1250: recall scoring with single decay half-life -- THE BUG)
@daem0nmcp/similarity.py (lines 386-421: calculate_memory_decay function)
@daem0nmcp/config.py (lines 19-140: Settings class)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix per-category decay and create auto_detect.py module</name>
  <files>daem0nmcp/auto_detect.py, daem0nmcp/memory.py, daem0nmcp/config.py</files>
  <action>
  1. CREATE `daem0nmcp/auto_detect.py` with:
     - `NOISE_PATTERNS`: List of compiled regex patterns that reject greetings, pleasantries, status responses, filler, Claude's own questions, and bare acknowledgments. Use `re.compile(..., re.IGNORECASE)` for each. Patterns from research:
       - `r'^(hi|hello|hey|good\s+(morning|afternoon|evening)|bye|goodbye|see you|take care)\b'`
       - `r'^(thanks?|thank you|you\'re welcome|no problem|sure thing)\b'`
       - `r'^(I\'m (good|fine|okay|ok|alright|great|doing well|not bad))\b'`
       - `r'^(um+|uh+|hmm+|well|so|anyway|actually|basically)\b'`
       - `r'^(can you|could you|would you|let me|shall I|do you want)\b'`
       - `r'^(yes|no|yeah|yep|nope|nah|okay|ok|sure|right|got it|I see)\b'`
     - `MIN_CONTENT_LENGTH = 15` (characters)
     - `MIN_WORD_COUNT = 4` (words)
     - `DUPLICATE_SIMILARITY_THRESHOLD = 0.85`
     - `AUTO_DECAY_MULTIPLIER = 0.7` (auto-detected memories get 70% of normal half-life)
     - `CATEGORY_HALF_LIVES` dict mapping non-permanent categories to their half-life in days:
       `{'interest': 90.0, 'goal': 90.0, 'emotion': 30.0, 'concern': 30.0, 'context': 14.0}`
     - `validate_auto_memory(content: str, confidence: float, settings: Optional[Settings] = None) -> dict`:
       - Strips and lowercases content
       - Checks each NOISE_PATTERN with `re.match` -- if match, return `{"valid": False, "reason": "noise_filter"}`
       - Checks `len(stripped) < MIN_CONTENT_LENGTH` -- return `{"valid": False, "reason": "too_short"}`
       - Checks `len(stripped.split()) < MIN_WORD_COUNT` -- return `{"valid": False, "reason": "too_few_words"}`
       - Read thresholds from settings if provided, else use defaults (0.95 and 0.70)
       - If `confidence >= high_threshold`: return `{"valid": True, "action": "auto_store"}`
       - If `confidence >= medium_threshold`: return `{"valid": True, "action": "suggest"}`
       - Else: return `{"valid": False, "reason": "low_confidence"}`

  2. MODIFY `daem0nmcp/config.py` -- Add to Settings class (after the `dream_community_staleness_threshold` line, around line 130):
     ```python
     # Auto-detection settings
     auto_detect_confidence_high: float = 0.95      # >= this: auto-store
     auto_detect_confidence_medium: float = 0.70     # >= this: suggest confirmation
     auto_decay_multiplier: float = 0.7              # Auto-detected memories decay at 70% of normal half-life
     ```

  3. MODIFY `daem0nmcp/memory.py` -- Fix the recall scoring decay logic (lines 1230-1235). Replace:
     ```python
     if getattr(mem, 'is_permanent', False) or (set(mem_categories) & PERMANENT_CATEGORIES):
         decay = 1.0
     else:
         decay = calculate_memory_decay(mem.created_at, decay_half_life_days)
     ```
     With:
     ```python
     if getattr(mem, 'is_permanent', False) or (set(mem_categories) & PERMANENT_CATEGORIES):
         decay = 1.0
     else:
         # Per-category decay: use the slowest (most generous) rate among categories
         from .auto_detect import CATEGORY_HALF_LIVES, AUTO_DECAY_MULTIPLIER
         half_lives = [
             CATEGORY_HALF_LIVES[cat]
             for cat in mem_categories
             if cat in CATEGORY_HALF_LIVES
         ]
         effective_half_life = max(half_lives) if half_lives else decay_half_life_days

         # Auto-detected memories decay faster than explicit ones
         mem_tags = getattr(mem, 'tags', None) or []
         if isinstance(mem_tags, str):
             import json
             try:
                 mem_tags = json.loads(mem_tags)
             except (json.JSONDecodeError, TypeError):
                 mem_tags = []
         if "auto" in mem_tags and "explicit" not in mem_tags:
             effective_half_life *= AUTO_DECAY_MULTIPLIER

         decay = calculate_memory_decay(mem.created_at, effective_half_life)
     ```
     NOTE: Move the import to the top of the file with other imports (not inline). The inline import above is for illustration -- place `from .auto_detect import CATEGORY_HALF_LIVES, AUTO_DECAY_MULTIPLIER` at the top of memory.py with the other imports from the same package. Handle the try/except ImportError pattern consistently with the rest of memory.py.

     IMPORTANT: The `mem.tags` field is stored as JSON in SQLite. Check how other code reads it -- if it comes back as a string, parse it. If it comes back as a list (from JSON column type), use directly. Look at how `_infer_tags` result is stored and how tags are read back in other places (e.g., daem0n_forget.py or daem0n_profile.py) to match the pattern.
  </action>
  <verify>
  - `python -c "from daem0nmcp.auto_detect import validate_auto_memory, CATEGORY_HALF_LIVES, AUTO_DECAY_MULTIPLIER, NOISE_PATTERNS"` succeeds
  - `python -c "from daem0nmcp.memory import MemoryManager"` succeeds (no import errors from the decay fix)
  - `python -c "from daem0nmcp.config import Settings; s = Settings(); print(s.auto_detect_confidence_high, s.auto_decay_multiplier)"` prints `0.95 0.7`
  </verify>
  <done>
  - auto_detect.py exists with validate_auto_memory(), NOISE_PATTERNS, CATEGORY_HALF_LIVES, AUTO_DECAY_MULTIPLIER
  - memory.py recall scoring uses per-category half-lives from CATEGORY_HALF_LIVES
  - memory.py applies AUTO_DECAY_MULTIPLIER when tags contain "auto" but not "explicit"
  - config.py has auto_detect_confidence_high, auto_detect_confidence_medium, auto_decay_multiplier settings
  </done>
</task>

<task type="auto">
  <name>Task 2: Tests for noise filter, confidence routing, and per-category decay</name>
  <files>tests/test_auto_detect.py, tests/test_similarity.py</files>
  <action>
  1. CREATE `tests/test_auto_detect.py` with a TestValidateAutoMemory class covering:

     **Noise filter tests:**
     - `test_rejects_greeting_hi`: `validate_auto_memory("hi there", 0.95)` returns `{"valid": False, "reason": "noise_filter"}`
     - `test_rejects_greeting_hello`: `validate_auto_memory("hello", 0.95)` returns noise_filter
     - `test_rejects_thank_you`: `validate_auto_memory("thank you so much", 0.95)` returns noise_filter
     - `test_rejects_status_response`: `validate_auto_memory("I'm good thanks", 0.95)` returns noise_filter
     - `test_rejects_filler`: `validate_auto_memory("um well actually", 0.95)` returns noise_filter
     - `test_rejects_acknowledgment`: `validate_auto_memory("yeah sure okay", 0.95)` returns noise_filter

     **Quality check tests:**
     - `test_rejects_too_short`: `validate_auto_memory("likes dogs", 0.95)` returns `{"valid": False, "reason": "too_short"}` (10 chars < 15)
     - `test_rejects_too_few_words`: `validate_auto_memory("sister is Sarah", 0.95)` -- exactly 3 words, under MIN_WORD_COUNT=4, returns too_few_words. NOTE: adjust test content to be >=15 chars but <4 words.

     **Confidence routing tests:**
     - `test_high_confidence_auto_stores`: `validate_auto_memory("User's sister Sarah lives in Portland Oregon", 0.98)` returns `{"valid": True, "action": "auto_store"}`
     - `test_medium_confidence_suggests`: `validate_auto_memory("User mentioned going to the gym regularly", 0.80)` returns `{"valid": True, "action": "suggest"}`
     - `test_low_confidence_skips`: `validate_auto_memory("User might have mentioned something about cooking", 0.50)` returns `{"valid": False, "reason": "low_confidence"}`
     - `test_boundary_high_at_095`: `validate_auto_memory("User works as a software engineer at Google", 0.95)` returns auto_store (boundary test)
     - `test_boundary_medium_at_070`: `validate_auto_memory("User seemed interested in woodworking projects", 0.70)` returns suggest

     **Valid content tests:**
     - `test_accepts_personal_fact`: `validate_auto_memory("User's name is Sarah and she lives in Portland", 0.96)` returns auto_store
     - `test_accepts_relationship_info`: `validate_auto_memory("User has a sister named Maria who lives nearby", 0.95)` returns auto_store

  2. ADD to `tests/test_similarity.py` in the existing TestMemoryDecay class:
     - `test_category_half_lives_defined`: Import CATEGORY_HALF_LIVES from auto_detect, assert interest=90.0, goal=90.0, emotion=30.0, concern=30.0, context=14.0
     - `test_slow_decay_category_longer_halflife`: Compare `calculate_memory_decay(60_days_ago, 90.0)` vs `calculate_memory_decay(60_days_ago, 30.0)` -- the 90-day version should have significantly higher weight
     - `test_auto_decay_multiplier_reduces_halflife`: Compare `calculate_memory_decay(60_days_ago, 90.0)` vs `calculate_memory_decay(60_days_ago, 90.0 * 0.7)` -- the multiplied version should have lower weight

  Run: `python -m pytest tests/test_auto_detect.py tests/test_similarity.py -v`
  </action>
  <verify>
  - `python -m pytest tests/test_auto_detect.py -v` -- all tests pass
  - `python -m pytest tests/test_similarity.py::TestMemoryDecay -v` -- all tests pass (existing + new)
  - `python -m pytest tests/test_daem0n_tools.py -v` -- no regressions (existing 37 tests still pass)
  </verify>
  <done>
  - test_auto_detect.py has 15+ tests covering noise filter, quality checks, confidence routing, and valid content acceptance
  - test_similarity.py has 3 new tests verifying per-category decay math
  - All existing tests pass without regression
  </done>
</task>

</tasks>

<verification>
1. `python -c "from daem0nmcp.auto_detect import validate_auto_memory"` -- module imports cleanly
2. `python -c "from daem0nmcp.memory import MemoryManager"` -- decay fix doesn't break imports
3. `python -m pytest tests/test_auto_detect.py tests/test_similarity.py::TestMemoryDecay -v` -- all new tests pass
4. `python -m pytest tests/test_daem0n_tools.py -v` -- no regressions
</verification>

<success_criteria>
- Per-category decay rates are implemented and tested (interest/goal=90d, emotion/concern=30d, context=14d)
- Auto-detected memories (tags contain "auto") decay at 70% of normal half-life
- Noise filter rejects greetings, filler, acknowledgments, and short/sparse content
- Confidence routing correctly routes to auto_store (>=0.95), suggest (0.70-0.95), or skip (<0.70)
- All existing tests pass without regression
</success_criteria>

<output>
After completion, create `.planning/phases/04-auto-detection-memory-decay/04-01-SUMMARY.md`
</output>
